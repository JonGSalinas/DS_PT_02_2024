{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios\n",
    "\n",
    "Completa los siguientes ejercicios utilizando lo que hemos aprendido hasta y los datos del directorio ejercicios/:\n",
    "\n",
    "1. Queremos ver los datos de las acciones de Facebook, Apple, Amazon, Netflix y Google (FAANG), pero nos dieron cada uno como un archivo CSV separado. Combínelos en un único archivo y guarde el dataframe de los datos FAANG como faang para el resto de los ejercicios:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Crea la carpeta faang. Mueve los archivos aapl.csv, amzn.csv, fb.csv, goog.csv y nflx.csv a dicha carpeta\n",
    "# Lee los archivos usando un bucle\n",
    "import os\n",
    "import shutil\n",
    "os.makedirs(\"faang\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in [\"aapl.csv\", \"amzn.csv\", \"fb.csv\", \"goog.csv\", \"nflx.csv\"]:\n",
    "    shutil.move(f, f\"faang/{f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta también funciona\n",
    "#for f in [\"aapl.csv\", \"amzn.csv\", \"fb.csv\", \"goog.csv\", \"nflx.csv\"]:\n",
    "#    shutil.move(f, \"faang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"fb.csv\".split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = []\n",
    "import pandas as pd\n",
    "for file in os.listdir(\"faang\"):\n",
    "    tmp = pd.read_csv(f\"faang/{file}\")\n",
    "    tmp[\"ticker\"] = file.split(\".\")[0]\n",
    "    lista.append(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang = pd.concat(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang.to_csv(\"faang.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b) Añade una columna a cada dataframe, llamalo ticker, indicando el símbolo del ticker al que corresponde (el de Apple es AAPL, por ejemplo);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c) Agréguelos en un dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d) Guarda el resultado en un archivo CSV llamado faang.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang[\"open\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang[faang[\"open\"]==faang[\"open\"].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang.groupby([\"ticker\"])[\"open\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang[\"mayor_100\"] = faang[\"open\"].apply(lambda x: x>=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mayor_100(x):\n",
    "    return x>=100\n",
    "faang[\"mayor_100_bis\"] = faang[\"open\"].apply(mayor_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrado(x):\n",
    "    if x<=50:\n",
    "        return \"Entre 0 y 50\"\n",
    "    elif 50<x<=100:\n",
    "        return \"Entre 51 y 100\"\n",
    "    elif 100<x<=1000:\n",
    "        return \"Entre 101 y 1000\"\n",
    "    else:\n",
    "        return \"Más de 1000\"\n",
    "faang[\"filtro_Valor\"] = faang[\"open\"].apply(filtrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang[\"dist_media\"] = faang.groupby(\"ticker\")[\"open\"].transform(lambda x: x - x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medias = faang.groupby([\"ticker\"], as_index=False)[\"open\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medias.rename(columns={\"open\":\"media\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang[\"mim_max\"] = faang.groupby(\"ticker\")[\"open\"].transform(lambda x: (x - x.min())/(x.max()-x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang.groupby(\"ticker\")[\"mim_max\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medias.columns =[\"ticker\", \"media\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang.groupby([\"ticker\"])[[\"open\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang2 = pd.merge(faang, medias, on=[\"ticker\"], how=\"outer\", indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang2[\"dist_media_2\"] = faang2[\"open\"] - faang2[\"media\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(faang2[\"dist_media_2\"] != faang2[\"dist_media\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula la normalización min-max para cada ticker de los faang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula una columna que sea \"Sube\" si el valor de close era superior al de open y \"Baja\" en caso contrario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Con faang, utilice la conversión de tipos para convertir los valores de la columna de fecha en datetime y la columna de volumen en números enteros. A continuación, ordena por fecha y ticker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El csv tipo_cambio contiene los tipos de cambio entre USD y EUR para el 2018 (datos inventados). \n",
    "Añade la fecha para cada día del año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convierte la columna low de faang a euro usando merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convierte la columna low de faang a euro usando apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Encuentre las siete filas en faang con el valor más bajo para el volumen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. El Centro Europeo para la Prevención y el Control de las Enfermedades (ECDC) proporciona un conjunto de datos abierto sobre casos de COVID-19 denominado número diario de nuevos casos notificados de COVID-19 por país en todo el mundo (https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographicdistribution-covid-19-cases-worldwide). Este conjunto de datos se actualiza diariamente, pero utilizaremos una instantánea que contiene datos desde el 1 de enero de 2020 hasta el 18 de septiembre de 2020. Limpia y pivota los datos para que estén en formato ancho:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- a) Lea el archivo covid19_casos.csv.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- b) Cree una columna de fecha utilizando los datos de la columna dateRep y la función pd.to_datetime().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- c) Establece la columna de fecha como índice y ordena el índice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- d) Sustituye todas las apariciones de United_States_of_America y United_Kingdom por USA y UK, respectivamente. Sugerencia: el método replace() puede ejecutarse en todo el dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- e) Utilizando la columna countriesAndTerritories, filtre los datos de casos COVID-19 depurados hasta Argentina, Brasil, China, Colombia, India, Italia, México, Perú, Rusia, España, Turquía, Reino Unido y Estados Unidos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- f) Pivota los datos de modo que el índice contenga las fechas, las columnas contengan los nombres de los países y los valores sean los recuentos de casos (la columna de casos). \n",
    "# Asegúrate de rellenar los valores NaN con 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Intenta obtener el csv covid19_total_cases.csv a partir de covid19_cases.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basado en hechos reales (Iván Vallés) aunque los datos eran diferentes\n",
    "En este archivo se encuentran las medidas en kg para generar en una planta cierto producto químico \n",
    "http://www.adjoint-functors.net/su/web/314/R/NB10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analiza si es tiene las propiedades de una distribución normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analiza si es tiene las propiedades de una distribución normal tras eliminar los 3 outliers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analiza si es razonable pensar que la media es de 400kg tras eliminar los outliers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
